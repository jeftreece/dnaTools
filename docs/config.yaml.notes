---
# redux2 (1) {{{

# top_snp: defines what your top-level SNP is called out of the (usually
# large number of) possible shared SNP's

# skip_to: this allows you to start the program at a particular point
#     0 -> run whole programme
#    10 -> work only with already-unzipped files
#    20 -> do not re-extract the VCF calls
#    30 -> do not re-make the tree

# These flags define what actually gets done

# Unless MAKEREPORT is non-zero, the other reports will be based on the current report.csv
# MAKEREPORT = do the main reduction and create report.csv, else use an existing one
# MAKEAGES = perform age analysis
# MAKESHORTREPORT = make a shorter version of the report, collapsing the singleton section and removing the shared and inconsistent list of SNPs
# MAKEHTMLTREE = make an HTML version of the tree for easier visualisation
# CHECKDATA = display warnings and create lists if inconsistencies detected in report (0 = no; >0 = yes)
# SKIPZIP = skip certain parts of the script: see below
# ZIPUPDATEONLY = don't re-extract that already exist # There's a bug here somewhere!
# TESTFORREFPOS = test for positives in the references sequence and swap if needed: see below

# These flags set options for Jef Treece's unpacking script and other options
# They are not currently implemented

# zip_dir
# unzip_dir
# zips2_dir
# unzips2_dir

# if you only want a subset; add -d if unzip dir is already populated

# zip_set

# 0/1 - if 1: only run bash script; do not run clades.py for any operations
# if setting to 1 when previously run w/ 0, clear out the unzip directory first

# bash_only: True

# 0/1 - if 1: drop and recreate the database if running with BASHONLY=0 -- takes a few minutes
# recreate_db: True

# Notes on SKIPZIP
# Set SKIPZIP to >0 skip the labour-intensive parts of the script. Requires MAKEREPORT=TRUE
# This should only be done if you have run the script before on the same dataset!
# If set to 1, unzipping and VCF/BED file scanning will be ignored
#    Statistics generation, sorting of already-identified variants into good/bad/shared lists and clade sorting will still take place
#    This requires a successful (but not necessarily sorted) previous run.
# If set to 2, statistics generation is skipped. The statistics INCLUDING KIT NAMES will be taken from the header of the previous run.
#    It also uses the ORDER of the previous run, taken from order.txt
#    This requires a complete successful previous run
# If set to 3, SNP names aren't updated either. The previous SNP names are used.

# Notes on TESTFORREFPOS
# This should be set for clades where the reference sequence contains positives
# For BigY, this includes clades in R1b-U152 and G2.
# Clades which include ancestral SNPs of these regions (e.g. R, R1, R1b-M343, R1b-M269, R1b-L11, R1b-P312, ...)
# should have this set. However, self-contained branches of these clades do not (e.g. R1b-U106)
# as test results should be all positive or all negative for the group.

# The following parameters set the mutation rate for the age analysis.
# The rate is set in SNP mutations per year per *billion* base pairs.
# RATE0 and RATE1 give the lower and upper bounds for the 95% confidence interval.
# The rate you should use varies depending on the region of the chromsome involved.
# Rates are numerically lower in palindromic regions (see Helgason et al. 2015 and our own analyses).

# Rates for entire BigY test
# RATE=0.751
# RATE0=0.688
# RATE1=0.814

# Rates for standardised age.bed restricted region
# RATE=0.8186
# RATE0=0.7589
# RATE1=0.8771
# Rates for new age.bed (v. 0.7.0)

# rate: 0.8119
# rate_0: 0.7529
# rate_1: 0.8716

# ZEROAGE gives the date from which ages are computed
# ERRZEROAGE gives the (95% c.i.) +/- variation in this date for individual testers

# zero_age: 1950.33
# err_zero_age: 15.02

# That's it!

# List of required internal libraries:
#      positives-and-no-calls.py : This code reads the call status of SNPs from the BED files (Courtesy H.A.)
#      snps_hg19.csv : Contains SNP names. Can be updated, e.g.: wget http://ybrowse.org/gbrowse2/gff/snps_hg19.csv -O snps_hg19.csv
#      age.bed : Contains the regions used to count SNPs for age analysis.
#      poisson.tbl : A look-up table containing a matrix of Poisson functions
#      cpoisson.tbl : A look-up table containing 95% confidence intervals for cumulative Poisson statistics
#      events.svg : A customisable list of historical events to be included in the SVG file

# How to make a backup:
#      zip redux.zip redux.bash positives-and-no-calls.py age.bed poisson.tbl cpoisson.tbl implications.txt badlist.txt recurrencies.txt cladenames.txt events.svg treefoot.html merge-ignore.txt snps_hg19.csv 

# How to update cladenames.txt from a list of clades and substitutes in <official-tree.csv> formatted as:
# PARENT_SNP,
# ,CHILD_SNP
# ,CHILD_SNP
# awk 'NR==FNR {n[NR]=$1;o[NR]=$2;x=NR} NR!=FNR {for (i=1;i<=x;i++) if ($1==o[i] && $1!=n[i] && $1+0==0) print o[i],n[i]}' <(awk '$1!="" {split($1,pp," "); split(pp[1],p,"/")} $2!="" {split($2,qq," "); split(qq[1],q,"/")} NR>3 {if ($1=="") print p[1],q[1]; if ($2=="") print p[1],p[1]}' FS=, official-tree.csv  | sed 's/In://Ig' | grep '[0-9]') <(awk '{print $16}' final-ages.txt) >> cladenames.txt

# }}}
# redux2 (2) {{{

# names = """
# FTDNA345238Newell.zip, 345238, Newell
# 155941_BigY_RawData_20140911-1.zip, 155941, Unknown
# Lee 237414 BigY Raw Data.zip, 237414, Lee
# U106_515653_Hogenmiller_BigY_RawData_2016_11_20.zip, 515653, Hogenmiller
# bigy-Bettinger57020.zip, 57020, Bettinger
# """
# -----end hand-editing

# }}}
# redux2 (3) {{{

# Set start date for timing points
# Note: I believe this needs to be taken out of YAML. keeping her for now.
# T0: `date +%s.%N`
# This is the number of columns on the left-hand side of the CSV reports
# left_cols: 17
# Use is currently under development

# }}}
# clades {{{

# Set verbosity of messages
# verbosity: 30

# Sets directories and other input files
# zip_dir = "zip/"
# unzip_dir = "unzip/"

# The list of SNPs used as a reference
# Get this using:
# call(["source","webupdate.scr"])
# which runs:
#   wget http://ybrowse.org/gbrowse2/gff/snps_hg19.csv -O snps_hg19.csv
#   awk '{print $4,$5,$9,$11,$12}' FS='","' snps_hg19.csv | sort -nk1 | \
#   awk 'NR>1 {if (a!=$1) {print a,b,c,d,e,f; c=""}} {x=$0;a=$1;b=$2;c=length(c)>0?c"/"$3:$3;d=$4;e=$5;f=$6}' OFS='\t' > snps_hg19.tsv
# to convert it to TSV format with one line per position. Unfortunately,
# there doesn't seem to be a simple Pythonic way of reading in the original CSV
# file due to the quotes.

# b37_snp_file: "snps_hg19.csv"
# b38_snp_file: "snps_hg38.csv"

# This defines whether tables get made again
# drop_tables: 1

# }}}
